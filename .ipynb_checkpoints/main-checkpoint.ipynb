{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f630e4a8-349c-4b27-8793-9d4ecd2b87ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit transactions:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/1/2022</td>\n",
       "      <td>APPLE.COM/BILL           866-712-7753 ON</td>\n",
       "      <td>-79.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/2/2022</td>\n",
       "      <td>LCBO/RAO #0393           LONDON       ON  (APP...</td>\n",
       "      <td>-9.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/2/2022</td>\n",
       "      <td>UBER* TRIP               TORONTO      ON</td>\n",
       "      <td>-18.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/2/2022</td>\n",
       "      <td>LOST LOVE                LONDON       ON  (APP...</td>\n",
       "      <td>-19.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/2/2022</td>\n",
       "      <td>LOST LOVE                LONDON       ON  (APP...</td>\n",
       "      <td>-19.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>3/30/2023</td>\n",
       "      <td>LUCY'S                   LONDON       ON  (APP...</td>\n",
       "      <td>-57.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>3/30/2023</td>\n",
       "      <td>IVEY BUSINESS SCHOOL     LONDON       ON  (APP...</td>\n",
       "      <td>-5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>3/30/2023</td>\n",
       "      <td>IVEY BUSINESS SCHOOL     LONDON       ON  (APP...</td>\n",
       "      <td>-8.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>3/31/2023</td>\n",
       "      <td>CHATIME CF MASONVILLE    LONDON       ON  (APP...</td>\n",
       "      <td>-6.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3/31/2023</td>\n",
       "      <td>MACS SUSHI               LONDON       ON  (APP...</td>\n",
       "      <td>-16.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                               desc  amount\n",
       "0     9/1/2022          APPLE.COM/BILL           866-712-7753 ON   -79.09\n",
       "1     9/2/2022  LCBO/RAO #0393           LONDON       ON  (APP...   -9.40\n",
       "2     9/2/2022          UBER* TRIP               TORONTO      ON   -18.85\n",
       "3     9/2/2022  LOST LOVE                LONDON       ON  (APP...  -19.55\n",
       "4     9/2/2022  LOST LOVE                LONDON       ON  (APP...  -19.55\n",
       "..         ...                                                ...     ...\n",
       "409  3/30/2023  LUCY'S                   LONDON       ON  (APP...  -57.34\n",
       "410  3/30/2023  IVEY BUSINESS SCHOOL     LONDON       ON  (APP...   -5.97\n",
       "411  3/30/2023  IVEY BUSINESS SCHOOL     LONDON       ON  (APP...   -8.98\n",
       "412  3/31/2023  CHATIME CF MASONVILLE    LONDON       ON  (APP...   -6.78\n",
       "413  3/31/2023  MACS SUSHI               LONDON       ON  (APP...  -16.93\n",
       "\n",
       "[414 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debit transactions:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>dash</th>\n",
       "      <th>desc</th>\n",
       "      <th>recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/1/2022</td>\n",
       "      <td>-60.00</td>\n",
       "      <td>-</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>FREE INTERAC E-TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/3/2022</td>\n",
       "      <td>39.44</td>\n",
       "      <td>-</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>FREE INTERAC E-TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/3/2022</td>\n",
       "      <td>-130.00</td>\n",
       "      <td>-</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>FREE INTERAC E-TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/6/2022</td>\n",
       "      <td>-15.50</td>\n",
       "      <td>-</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>FREE INTERAC E-TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/6/2022</td>\n",
       "      <td>-400.00</td>\n",
       "      <td>-</td>\n",
       "      <td>Customer Transfer Dr.</td>\n",
       "      <td>MB-CREDIT CARD/LOC PAY.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>3/30/2023</td>\n",
       "      <td>500.00</td>\n",
       "      <td>-</td>\n",
       "      <td>Federal Payment</td>\n",
       "      <td>CANADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3/31/2023</td>\n",
       "      <td>311.58</td>\n",
       "      <td>-</td>\n",
       "      <td>Payroll Deposit</td>\n",
       "      <td>Icon HR Consultants Canada,CPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>3/31/2023</td>\n",
       "      <td>-95.27</td>\n",
       "      <td>-</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>FREE INTERAC E-TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>3/31/2023</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-</td>\n",
       "      <td>POS Purchase</td>\n",
       "      <td>OPOS UBER CANADA         TORON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>3/31/2023</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-</td>\n",
       "      <td>Correction</td>\n",
       "      <td>OPOS UBER CANADA         TORON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  amount dash                     desc  \\\n",
       "0     9/1/2022  -60.00    -  WITHDRAWAL                \n",
       "1     9/3/2022   39.44    -  DEPOSIT                   \n",
       "2     9/3/2022 -130.00    -  WITHDRAWAL                \n",
       "3     9/6/2022  -15.50    -  WITHDRAWAL                \n",
       "4     9/6/2022 -400.00    -  Customer Transfer Dr.     \n",
       "..         ...     ...  ...                      ...   \n",
       "202  3/30/2023  500.00    -  Federal Payment           \n",
       "203  3/31/2023  311.58    -  Payroll Deposit           \n",
       "204  3/31/2023  -95.27    -  WITHDRAWAL                \n",
       "205  3/31/2023   -1.02    -  POS Purchase              \n",
       "206  3/31/2023    1.02    -  Correction                \n",
       "\n",
       "                          recipient  \n",
       "0           FREE INTERAC E-TRANSFER  \n",
       "1           FREE INTERAC E-TRANSFER  \n",
       "2           FREE INTERAC E-TRANSFER  \n",
       "3           FREE INTERAC E-TRANSFER  \n",
       "4           MB-CREDIT CARD/LOC PAY.  \n",
       "..                              ...  \n",
       "202   CANADA                         \n",
       "203  Icon HR Consultants Canada,CPT  \n",
       "204         FREE INTERAC E-TRANSFER  \n",
       "205  OPOS UBER CANADA         TORON  \n",
       "206  OPOS UBER CANADA         TORON  \n",
       "\n",
       "[207 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXTRACT\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import ssl\n",
    "import certifi\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Specify the CSV file path\n",
    "cr_path = 'fin_records/cr_hist.csv'\n",
    "db_path = 'fin_records/db_hist.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "cr_col_names = ['date', 'desc', 'amount']\n",
    "cr_hist = pd.read_csv(cr_path, names=cr_col_names, header=None)\n",
    "\n",
    "db_col_names = ['date', 'amount', 'dash', 'desc', 'recipient']\n",
    "db_hist = pd.read_csv(db_path, names=db_col_names, header=None)\n",
    "\n",
    "# Display the contents of the DataFrame\n",
    "print('Credit transactions:\\n')\n",
    "display(cr_hist)\n",
    "print('Debit transactions:\\n')\n",
    "display(db_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a676ed96-1a14-4d59-9ea1-c310b120705f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>APPLE.COM/BILL           866-712-7753 ON</td>\n",
       "      <td>-79.09</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>WITHDRAWAL             FREE INTERAC E-TRANSFER</td>\n",
       "      <td>-60.00</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>UBER* TRIP               TORONTO      ON</td>\n",
       "      <td>-18.85</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>LOST LOVE                LONDON       ON  (APP...</td>\n",
       "      <td>-19.55</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>LOST LOVE                LONDON       ON  (APP...</td>\n",
       "      <td>-19.55</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>WITHDRAWAL             FREE INTERAC E-TRANSFER</td>\n",
       "      <td>-95.27</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>CHATIME CF MASONVILLE    LONDON       ON  (APP...</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>MACS SUSHI               LONDON       ON  (APP...</td>\n",
       "      <td>-16.93</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>POS Purchase           OPOS UBER CANADA       ...</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>Correction             OPOS UBER CANADA       ...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                               desc  amount  \\\n",
       "0   2022-09-01          APPLE.COM/BILL           866-712-7753 ON   -79.09   \n",
       "414 2022-09-01     WITHDRAWAL             FREE INTERAC E-TRANSFER  -60.00   \n",
       "2   2022-09-02          UBER* TRIP               TORONTO      ON   -18.85   \n",
       "3   2022-09-02  LOST LOVE                LONDON       ON  (APP...  -19.55   \n",
       "4   2022-09-02  LOST LOVE                LONDON       ON  (APP...  -19.55   \n",
       "..         ...                                                ...     ...   \n",
       "618 2023-03-31     WITHDRAWAL             FREE INTERAC E-TRANSFER  -95.27   \n",
       "412 2023-03-31  CHATIME CF MASONVILLE    LONDON       ON  (APP...   -6.78   \n",
       "413 2023-03-31  MACS SUSHI               LONDON       ON  (APP...  -16.93   \n",
       "619 2023-03-31  POS Purchase           OPOS UBER CANADA       ...   -1.02   \n",
       "620 2023-03-31  Correction             OPOS UBER CANADA       ...    1.02   \n",
       "\n",
       "          category  \n",
       "0    Uncategorized  \n",
       "414  Uncategorized  \n",
       "2    Uncategorized  \n",
       "3    Uncategorized  \n",
       "4    Uncategorized  \n",
       "..             ...  \n",
       "618  Uncategorized  \n",
       "412  Uncategorized  \n",
       "413  Uncategorized  \n",
       "619  Uncategorized  \n",
       "620  Uncategorized  \n",
       "\n",
       "[621 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRANSFORM\n",
    "\n",
    "# Combine description column and recipient column of debit history\n",
    "db_hist['desc'] = db_hist['desc'] + db_hist['recipient'].fillna('')\n",
    "\n",
    "# Drop un-needed columns, add category column\n",
    "db_hist = db_hist.drop(['dash', 'recipient'], axis = 1)\n",
    "\n",
    "# Re-order columns\n",
    "db_hist = db_hist[['date','desc','amount']]\n",
    "\n",
    "# Combine 'Debit' and 'Credit' tables into a 'Comprehensive History' dataframe\n",
    "comp_hist = cr_hist.append(db_hist, ignore_index=True)\n",
    "comp_hist['category'] = 'Uncategorized'\n",
    "comp_hist['date']= pd.to_datetime(comp_hist['date'])\n",
    "comp_hist.sort_values(by=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba88c1f-0eda-495f-a352-354c4c45246e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete transactions between accounts\n",
    "cr_pmt_trns_pattern = r'FROM - |CREDIT CARD'\n",
    "comp_hist = comp_hist[~comp_hist['desc'].str.contains(cr_pmt_trns_pattern, regex=True, na=False)]\n",
    "\n",
    "# Read the JSON file\n",
    "with open(\"categories.json\", \"r\") as file:\n",
    "    category_patterns = json.load(file)\n",
    "    \n",
    "# Compile category patterns\n",
    "for category in category_patterns:\n",
    "    category_patterns[category] = [re.compile(pattern, re.IGNORECASE) for pattern in category_patterns[category]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1cae02-3c61-421f-ad3b-0b493884afee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>APPLE.COM/BILL           866-712-7753 ON</td>\n",
       "      <td>-79.09</td>\n",
       "      <td>Purchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>LCBO/RAO #0393           LONDON       ON  (APP...</td>\n",
       "      <td>-9.40</td>\n",
       "      <td>Partying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>UBER* TRIP               TORONTO      ON</td>\n",
       "      <td>-18.85</td>\n",
       "      <td>Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>LOST LOVE                LONDON       ON  (APP...</td>\n",
       "      <td>-19.55</td>\n",
       "      <td>Partying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>LOST LOVE                LONDON       ON  (APP...</td>\n",
       "      <td>-19.55</td>\n",
       "      <td>Partying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>Federal Payment        CANADA                 ...</td>\n",
       "      <td>500.00</td>\n",
       "      <td>Non-Routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>Payroll Deposit        Icon HR Consultants Can...</td>\n",
       "      <td>311.58</td>\n",
       "      <td>Earnings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>WITHDRAWAL             FREE INTERAC E-TRANSFER</td>\n",
       "      <td>-95.27</td>\n",
       "      <td>Shared Purchases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>POS Purchase           OPOS UBER CANADA       ...</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>Correction             OPOS UBER CANADA       ...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>Transportation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                               desc  amount  \\\n",
       "0   2022-09-01          APPLE.COM/BILL           866-712-7753 ON   -79.09   \n",
       "1   2022-09-02  LCBO/RAO #0393           LONDON       ON  (APP...   -9.40   \n",
       "2   2022-09-02          UBER* TRIP               TORONTO      ON   -18.85   \n",
       "3   2022-09-02  LOST LOVE                LONDON       ON  (APP...  -19.55   \n",
       "4   2022-09-02  LOST LOVE                LONDON       ON  (APP...  -19.55   \n",
       "..         ...                                                ...     ...   \n",
       "616 2023-03-30  Federal Payment        CANADA                 ...  500.00   \n",
       "617 2023-03-31  Payroll Deposit        Icon HR Consultants Can...  311.58   \n",
       "618 2023-03-31     WITHDRAWAL             FREE INTERAC E-TRANSFER  -95.27   \n",
       "619 2023-03-31  POS Purchase           OPOS UBER CANADA       ...   -1.02   \n",
       "620 2023-03-31  Correction             OPOS UBER CANADA       ...    1.02   \n",
       "\n",
       "             category  \n",
       "0           Purchases  \n",
       "1            Partying  \n",
       "2      Transportation  \n",
       "3            Partying  \n",
       "4            Partying  \n",
       "..                ...  \n",
       "616       Non-Routine  \n",
       "617          Earnings  \n",
       "618  Shared Purchases  \n",
       "619    Transportation  \n",
       "620    Transportation  \n",
       "\n",
       "[551 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to categorize based on the desc column\n",
    "def categorize(desc):\n",
    "    for category, patterns in category_patterns.items():\n",
    "        if any(pattern.search(desc) for pattern in patterns):\n",
    "            return category\n",
    "    return \"Other\"\n",
    "\n",
    "# Apply the categorization function\n",
    "comp_hist['category'] = comp_hist['desc'].apply(categorize)\n",
    "\n",
    "display(comp_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06ddc19-d327-4874-98da-13ed27cee72e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.000000000000001 % uncategorized.\n",
      "Top 10 frequent word segments:\n",
      "ON: 17\n",
      "(: 15\n",
      "APPLE: 15\n",
      "PAY: 15\n",
      "): 15\n",
      "LONDON: 10\n",
      "Provincial: 7\n",
      "Payment: 7\n",
      "CANADA: 7\n",
      "POS: 5\n"
     ]
    }
   ],
   "source": [
    "unid_count = len(comp_hist[comp_hist[\"category\"]==\"Other\"])\n",
    "print(round(unid_count/len(comp_hist), 2) * 100, \"% uncategorized.\")\n",
    "\n",
    "# Filter the DataFrame for records with the \"Other\" category\n",
    "other_records = comp_hist[comp_hist[\"category\"] == \"Other\"]\n",
    "\n",
    "# If not fully categorized, initiate GPT API catagorization process\n",
    "fully_categorized = False\n",
    "\n",
    "if(len(other_records) == 0):\n",
    "    fully_categorized = True\n",
    "    \n",
    "if(not fully_categorized):\n",
    "    # Tokenize the desc column\n",
    "    tokens = nltk.word_tokenize(\" \".join(other_records[\"desc\"].values))\n",
    "\n",
    "    # Count the frequency of each word segment\n",
    "    word_freq = Counter(tokens)\n",
    "\n",
    "    # Display the top frequent word segments\n",
    "    num_top_segments = 10  # Change this number to display more or fewer top segments\n",
    "    top_segments = word_freq.most_common(num_top_segments)\n",
    "\n",
    "    print(f\"Top {num_top_segments} frequent word segments:\")\n",
    "    for segment, count in top_segments:\n",
    "        print(f\"{segment}: {count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "683b9d56-cb5b-4c90-afdd-4b9c916049ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Purchases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 34\u001b[0m\n\u001b[1;32m     15\u001b[0m     config_string \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(config_data, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# System prompt to guide the response\u001b[39;00m\n\u001b[1;32m     19\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou are a categorizer AI. you take a list of transaction descriptions and return a matching list of categories. The categories are:\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124mDining Out, Groceries, Transportation, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m Non-Routine, Earnings, Partying, Shared Purchases, Purchases, and Medical.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124mAdditionally, a second list should be returned with a keyword found in the description that allowed you to identify the category.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124mFor each transaction, there must be a corresponding category and key word. this is to say their total counts must match.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124mDo not include any notes or comments other than the lists\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124mHere is the current category keywords for you to make better suggestions:\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124mexample input:\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124m STATION PARK CONVENIENCE LONDON       ON  (APPLE PAY) \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124mAmazon Web Services      www.amazon.caON \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mExample output:\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPurchases,Purchases\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mConvenience,Amazon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Filter the DataFrame for records with the \"Other\" category\u001b[39;00m\n\u001b[1;32m     38\u001b[0m other_records \u001b[38;5;241m=\u001b[39m comp_hist[comp_hist[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOther\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Purchases' is not defined"
     ]
    }
   ],
   "source": [
    "def chat_with_gpt(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "if( not fully_categorized):\n",
    "    # GPT Model to be used\n",
    "    gpt_model = 'gpt-4'\n",
    "    \n",
    "    # System prompt to guide the response\n",
    "    system_prompt = f\"you are a categorizer AI. you take a list of transaction descriptions and return a matching list of categories. The categories are:\\\n",
    "    Dining Out, Groceries, Transportation, \\\n",
    "     Non-Routine, Earnings, Partying, Shared Purchases, Purchases, and Medical.\\\n",
    "    ---\\\n",
    "    Additionally, a second list should be returned with a keyword found in the description that allowed you to identify the category.\\\n",
    "    For each transaction, there must be a corresponding category and key word. this is to say their total counts must match.\\\n",
    "    Do not include any notes or comments other than the lists\\\n",
    "    ---\\\n",
    "    example input:\\\n",
    "     STATION PARK CONVENIENCE LONDON       ON  (APPLE PAY) \\\n",
    "    Amazon Web Services      www.amazon.caON \\\n",
    "    Example output:\\\n",
    "    {Purchases,Purchases}\\\n",
    "    {Convenience,Amazon}\"\n",
    "\n",
    "    # Filter the DataFrame for records with the \"Other\" category\n",
    "    other_records = comp_hist[comp_hist[\"category\"] == \"Other\"]\n",
    "\n",
    "    # Get unique desc values\n",
    "    unique_desc = set(other_records[\"desc\"].values)\n",
    "\n",
    "    # Remove unwanted text (e.g., \"ON  (APPLE PAY)\")\n",
    "    unique_desc = {desc.replace(\"ON  (APPLE PAY)\", \"\") for desc in unique_desc}\n",
    "\n",
    "    # Concatenate the unique desc values into a single string\n",
    "    unid_desc = \", \".join(unique_desc)\n",
    "\n",
    "    # Get suggestions from GPT API\n",
    "    suggested_categories = {}\n",
    "    suggested_keywords = {}\n",
    "\n",
    "    # Formulate message and send to GPT API\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": unid_desc}\n",
    "    ]\n",
    "\n",
    "    response = chat_with_gpt(messages)\n",
    "\n",
    "    # Convert the GPT response into two lists, the first element being the categories and the second being the key words\n",
    "    response = response.split(\"}\")\n",
    "\n",
    "    # Strip unneccessary charcters\n",
    "    for index, i in enumerate(response):\n",
    "        response[index] = i.replace(\"{\", \"\")\n",
    "\n",
    "    # Split the strings into tokens and update the keyword config file and the data frame\n",
    "    suggested_categories = response[0].split(\", \")\n",
    "    suggested_keywords = response[1].split(\", \")\n",
    "\n",
    "    # Step 1: Write the suggested categories and keywords side by side into a text file\n",
    "    with open(\"suggested_categories_and_keywords.txt\", \"w\") as file:\n",
    "        for category, keyword in zip(suggested_categories, suggested_keywords):\n",
    "            file.write(f\"{category}, {keyword}\\n\")\n",
    "\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad8281c-8faa-4b47-83dd-635935a9ec8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dining Out': [re.compile('Tim Hortons', re.IGNORECASE), re.compile('McDonalds', re.IGNORECASE), re.compile('Starbucks', re.IGNORECASE), re.compile('Ubereats', re.IGNORECASE), re.compile('IVEY BUSINESS SCHOOL', re.IGNORECASE), re.compile('Izakaya', re.IGNORECASE), re.compile('keg', re.IGNORECASE), re.compile('Congee', re.IGNORECASE), re.compile('Lucy', re.IGNORECASE), re.compile('Lonestar', re.IGNORECASE), re.compile('Marble Slab', re.IGNORECASE), re.compile('Dennys', re.IGNORECASE), re.compile('Los Lobos', re.IGNORECASE), re.compile('Pho Lee', re.IGNORECASE), re.compile(\"Einstein's\", re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Katsu', re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Sushi Roncy', re.IGNORECASE), re.compile('Chess.com', re.IGNORECASE), re.compile('Sushi Roncy', re.IGNORECASE), re.compile('Mabels', re.IGNORECASE), re.compile('Coca Cola', re.IGNORECASE), re.compile('Barakats', re.IGNORECASE), re.compile('Cupbop Plus', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Burger Burger', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Los Lobos', re.IGNORECASE), re.compile('I Deal', re.IGNORECASE), re.compile('Rose', re.IGNORECASE), re.compile('Reunion Island', re.IGNORECASE), re.compile('Chatime', re.IGNORECASE), re.compile('Black Walnut', re.IGNORECASE), re.compile('Famous Player', re.IGNORECASE), re.compile('Macs Sushi', re.IGNORECASE), re.compile('Wave', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Beavertails', re.IGNORECASE), re.compile('Country Chalet', re.IGNORECASE), re.compile(\"Turtlejack's\", re.IGNORECASE), re.compile(\"Omzzy's\", re.IGNORECASE), re.compile('Bombay Bistro', re.IGNORECASE), re.compile('Amazon.ca', re.IGNORECASE), re.compile('Food Island', re.IGNORECASE), re.compile('Quynh Nhi', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Subway', re.IGNORECASE), re.compile(' Cora', re.IGNORECASE), re.compile('Gong Cha', re.IGNORECASE), re.compile('Sansotei', re.IGNORECASE), re.compile('Wild Heart', re.IGNORECASE), re.compile('Tokyo Smoke', re.IGNORECASE), re.compile('Mercantile', re.IGNORECASE), re.compile('Popeyes', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Koya', re.IGNORECASE), re.compile('Lonestar', re.IGNORECASE), re.compile('Marble Slab', re.IGNORECASE), re.compile('Dennys', re.IGNORECASE), re.compile('Los Lobos', re.IGNORECASE), re.compile('Pho Lee', re.IGNORECASE), re.compile(\"Einstein's\", re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Katsu', re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Sushi Roncy', re.IGNORECASE), re.compile('Chess.com', re.IGNORECASE), re.compile('Sushi Roncy', re.IGNORECASE), re.compile('Mabels', re.IGNORECASE), re.compile('Coca Cola', re.IGNORECASE), re.compile('Barakats', re.IGNORECASE), re.compile('Cupbop Plus', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Burger Burger', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Los Lobos', re.IGNORECASE), re.compile('I Deal', re.IGNORECASE), re.compile('Rose', re.IGNORECASE), re.compile('Reunion Island', re.IGNORECASE), re.compile('Chatime', re.IGNORECASE), re.compile('Black Walnut', re.IGNORECASE), re.compile('Famous Player', re.IGNORECASE), re.compile('Macs Sushi', re.IGNORECASE), re.compile('Wave', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Beavertails', re.IGNORECASE), re.compile('Country Chalet', re.IGNORECASE), re.compile(\"Turtlejack's\", re.IGNORECASE), re.compile(\"Omzzy's\", re.IGNORECASE), re.compile('Bombay Bistro', re.IGNORECASE), re.compile('Amazon.ca', re.IGNORECASE), re.compile('Food Island', re.IGNORECASE), re.compile('Quynh Nhi', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Subway', re.IGNORECASE), re.compile(' Cora', re.IGNORECASE), re.compile('Gong Cha', re.IGNORECASE), re.compile('Sansotei', re.IGNORECASE), re.compile('Wild Heart', re.IGNORECASE), re.compile('Tokyo Smoke', re.IGNORECASE), re.compile('Mercantile', re.IGNORECASE), re.compile('Popeyes', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Koya', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Chatime', re.IGNORECASE), re.compile('East Side Marios', re.IGNORECASE), re.compile('Fantail', re.IGNORECASE), re.compile('Coco', re.IGNORECASE), re.compile('Subway', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Popeyes', re.IGNORECASE), re.compile('Fantail', re.IGNORECASE), re.compile('Banjara', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('East', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Rocky Mountain', re.IGNORECASE), re.compile('Copper', re.IGNORECASE), re.compile('Lonestar', re.IGNORECASE), re.compile('Marble Slab', re.IGNORECASE), re.compile('Dennys', re.IGNORECASE), re.compile('Los Lobos', re.IGNORECASE), re.compile('Pho Lee', re.IGNORECASE), re.compile(\"Einstein's\", re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Katsu', re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Sushi Roncy', re.IGNORECASE), re.compile('Chess.com', re.IGNORECASE), re.compile('Sushi Roncy', re.IGNORECASE), re.compile('Mabels', re.IGNORECASE), re.compile('Coca Cola', re.IGNORECASE), re.compile('Barakats', re.IGNORECASE), re.compile('Cupbop Plus', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Burger Burger', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Los Lobos', re.IGNORECASE), re.compile('I Deal', re.IGNORECASE), re.compile('Rose', re.IGNORECASE), re.compile('Reunion Island', re.IGNORECASE), re.compile('Chatime', re.IGNORECASE), re.compile('Black Walnut', re.IGNORECASE), re.compile('Famous Player', re.IGNORECASE), re.compile('Macs Sushi', re.IGNORECASE), re.compile('Wave', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Beavertails', re.IGNORECASE), re.compile('Country Chalet', re.IGNORECASE), re.compile(\"Turtlejack's\", re.IGNORECASE), re.compile(\"Omzzy's\", re.IGNORECASE), re.compile('Bombay Bistro', re.IGNORECASE), re.compile('Amazon.ca', re.IGNORECASE), re.compile('Food Island', re.IGNORECASE), re.compile('Quynh Nhi', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Subway', re.IGNORECASE), re.compile(' Cora', re.IGNORECASE), re.compile('Gong Cha', re.IGNORECASE), re.compile('Sansotei', re.IGNORECASE), re.compile('Wild Heart', re.IGNORECASE), re.compile('Tokyo Smoke', re.IGNORECASE), re.compile('Mercantile', re.IGNORECASE), re.compile('Popeyes', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Koya', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Spoke', re.IGNORECASE), re.compile('Chatime', re.IGNORECASE), re.compile('East Side Marios', re.IGNORECASE), re.compile('Fantail', re.IGNORECASE), re.compile('Coco', re.IGNORECASE), re.compile('Subway', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Popeyes', re.IGNORECASE), re.compile('Fantail', re.IGNORECASE), re.compile('Banjara', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('East', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Rocky Mountain', re.IGNORECASE), re.compile('Copper', re.IGNORECASE)], 'Groceries': [re.compile('Walmart', re.IGNORECASE), re.compile('Costco', re.IGNORECASE), re.compile('Superstore', re.IGNORECASE), re.compile('Instacart', re.IGNORECASE), re.compile('Loblaws', re.IGNORECASE), re.compile('Sobey', re.IGNORECASE), re.compile('Wild Wing', re.IGNORECASE), re.compile('Wild Wing', re.IGNORECASE)], 'Transportation': [re.compile('Ubertrip', re.IGNORECASE), re.compile('Lyft', re.IGNORECASE), re.compile('TRIP', re.IGNORECASE), re.compile('Uber', re.IGNORECASE), re.compile('presto', re.IGNORECASE), re.compile('U Need A Cab', re.IGNORECASE), re.compile('Earls', re.IGNORECASE), re.compile('Northwood', re.IGNORECASE), re.compile('U Need A Cab', re.IGNORECASE), re.compile('Earls', re.IGNORECASE), re.compile('Northwood', re.IGNORECASE)], 'Non-Routine': [re.compile('Student Loan', re.IGNORECASE), re.compile('GST', re.IGNORECASE), re.compile('tuition', re.IGNORECASE), re.compile('Investment', re.IGNORECASE), re.compile('Federal', re.IGNORECASE), re.compile('Adjustment', re.IGNORECASE), re.compile('Customer Transfer', re.IGNORECASE), re.compile('Via rail', re.IGNORECASE), re.compile('Flying Squirrel', re.IGNORECASE), re.compile('Famous Player', re.IGNORECASE), re.compile('IVEY', re.IGNORECASE), re.compile('Ghost Blasters', re.IGNORECASE), re.compile('Wizards', re.IGNORECASE), re.compile('Flying Squirrel', re.IGNORECASE), re.compile('Famous Player', re.IGNORECASE), re.compile('IVEY', re.IGNORECASE), re.compile('Ghost Blasters', re.IGNORECASE), re.compile('Wizards', re.IGNORECASE), re.compile('Club Monaco', re.IGNORECASE), re.compile('Bandit', re.IGNORECASE), re.compile('Flying Squirrel', re.IGNORECASE), re.compile('Famous Player', re.IGNORECASE), re.compile('IVEY', re.IGNORECASE), re.compile('Ghost Blasters', re.IGNORECASE), re.compile('Wizards', re.IGNORECASE), re.compile('Club Monaco', re.IGNORECASE), re.compile('Bandit', re.IGNORECASE)], 'Earnings': [re.compile('Payroll', re.IGNORECASE)], 'Partying': [re.compile('Lost Love', re.IGNORECASE), re.compile('Ceeps', re.IGNORECASE), re.compile('Dellah', re.IGNORECASE), re.compile('LCBO', re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Steam', re.IGNORECASE), re.compile('Chucks Roadhouse', re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Steam', re.IGNORECASE), re.compile('Chucks Roadhouse', re.IGNORECASE), re.compile(\"Poacher's Arms\", re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Barking Frog', re.IGNORECASE), re.compile('Steam', re.IGNORECASE), re.compile('Chucks Roadhouse', re.IGNORECASE), re.compile(\"Poacher's Arms\", re.IGNORECASE)], 'Shared Purchases': [re.compile('INTERAC', re.IGNORECASE)], 'Purchases': [re.compile('APPLE.COM/BILL', re.IGNORECASE), re.compile('AMZN', re.IGNORECASE), re.compile('Uniqlo', re.IGNORECASE), re.compile('peace collective', re.IGNORECASE), re.compile('Vitaly', re.IGNORECASE), re.compile('Sweater', re.IGNORECASE), re.compile('Ozen', re.IGNORECASE), re.compile('n15', re.IGNORECASE), re.compile('Convenience', re.IGNORECASE), re.compile('Amazon', re.IGNORECASE), re.compile('Oculus', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Richmond', re.IGNORECASE), re.compile('Amazon', re.IGNORECASE), re.compile('Hot Topic', re.IGNORECASE), re.compile('Dineen', re.IGNORECASE), re.compile('Chess.com', re.IGNORECASE), re.compile('Apple Store', re.IGNORECASE), re.compile('Petrocan', re.IGNORECASE), re.compile('Apple.com', re.IGNORECASE), re.compile('Apple.com', re.IGNORECASE), re.compile('Tonality', re.IGNORECASE), re.compile('Amazon.ca', re.IGNORECASE), re.compile('Eventbrite', re.IGNORECASE), re.compile('Winners', re.IGNORECASE), re.compile('Convenience', re.IGNORECASE), re.compile('Amazon', re.IGNORECASE), re.compile('Oculus', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Richmond', re.IGNORECASE), re.compile('Amazon', re.IGNORECASE), re.compile('Hot Topic', re.IGNORECASE), re.compile('Dineen', re.IGNORECASE), re.compile('Chess.com', re.IGNORECASE), re.compile('Apple Store', re.IGNORECASE), re.compile('Petrocan', re.IGNORECASE), re.compile('Apple.com', re.IGNORECASE), re.compile('Apple.com', re.IGNORECASE), re.compile('Tonality', re.IGNORECASE), re.compile('Amazon.ca', re.IGNORECASE), re.compile('Eventbrite', re.IGNORECASE), re.compile('Winners', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Tonality', re.IGNORECASE), re.compile('Convenience', re.IGNORECASE), re.compile('Amazon', re.IGNORECASE), re.compile('Oculus', re.IGNORECASE), re.compile('Dollarama', re.IGNORECASE), re.compile('Richmond', re.IGNORECASE), re.compile('Amazon', re.IGNORECASE), re.compile('Hot Topic', re.IGNORECASE), re.compile('Dineen', re.IGNORECASE), re.compile('Chess.com', re.IGNORECASE), re.compile('Apple Store', re.IGNORECASE), re.compile('Petrocan', re.IGNORECASE), re.compile('Apple.com', re.IGNORECASE), re.compile('Apple.com', re.IGNORECASE), re.compile('Tonality', re.IGNORECASE), re.compile('Amazon.ca', re.IGNORECASE), re.compile('Eventbrite', re.IGNORECASE), re.compile('Winners', re.IGNORECASE), re.compile(\"McDonald's\", re.IGNORECASE), re.compile('Tonality', re.IGNORECASE)], 'Medical': [re.compile('Eyes On Sheppard', re.IGNORECASE), re.compile('Insurance', re.IGNORECASE), re.compile('APOLLO', re.IGNORECASE), re.compile('Dental', re.IGNORECASE)]}\n"
     ]
    }
   ],
   "source": [
    "    # Step 3: Read the updated text file and parse the categories and keywords\n",
    "    with open(\"suggested_categories_and_keywords.txt\", \"r\") as file:\n",
    "        updated_suggestions = [line.strip().split(\", \") for line in file.readlines()]\n",
    "\n",
    "    updated_categories = [suggestion[0] for suggestion in updated_suggestions]\n",
    "    updated_keywords = [suggestion[1] for suggestion in updated_suggestions]\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    # Step 4: Update the keyword config file and the DataFrame with the parsed information\n",
    "    for category, keyword in zip(updated_categories, updated_keywords):\n",
    "        category_patterns[category].append(re.compile(keyword, re.IGNORECASE))\n",
    "\n",
    "    print(category_patterns)\n",
    "    # Save the updated category_patterns to the JSON file\n",
    "    with open(\"categories.json\", \"w\") as file:\n",
    "        json.dump({category: [pattern.pattern for pattern in patterns] for category, patterns in category_patterns.items()}, file)\n",
    "\n",
    "    # Apply the updated categorization function to the DataFrame\n",
    "    comp_hist['category'] = comp_hist['desc'].apply(categorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f119a339-8b27-4ca8-8ede-21adc6a19950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOAD\n",
    "\n",
    "comp_hist.to_csv('fin_records/comp_hist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d21180-830f-4fdf-ac2e-6caf4ab04557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
